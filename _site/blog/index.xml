<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Ayush Thakur</title>
<link>https://ayusht.dev/blog/</link>
<atom:link href="https://ayusht.dev/blog/index.xml" rel="self" type="application/rss+xml"/>
<description>Machine Learning Engineer &amp; Google Developer Expert</description>
<generator>quarto-1.4.543</generator>
<lastBuildDate>Mon, 19 Feb 2024 18:30:00 GMT</lastBuildDate>
<item>
  <title>A Practical Guide to LLM Evaluation</title>
  <dc:creator>Ayush Thakur</dc:creator>
  <link>https://ayusht.dev/blog/posts/llm-evaluation.html</link>
  <description><![CDATA[ 




<section id="a-practical-guide-to-llm-evaluation" class="level1">
<h1>A Practical Guide to LLM Evaluation</h1>
<p>As Large Language Models (LLMs) become increasingly central to AI applications, robust evaluation becomes essential. It’s not enough to simply deploy an LLM and hope for the best – we need systematic ways to assess their performance across multiple dimensions.</p>
<p>In this article, I’ll share a practical approach to LLM evaluation, drawing from my experience building evaluation pipelines with Weights &amp; Biases Sweeps.</p>
<section id="why-llm-evaluation-is-challenging" class="level2">
<h2 class="anchored" data-anchor-id="why-llm-evaluation-is-challenging">Why LLM Evaluation is Challenging</h2>
<p>Unlike traditional ML models where metrics like accuracy or F1 score might suffice, LLMs present unique evaluation challenges:</p>
<ol type="1">
<li><strong>Multiple dimensions of quality</strong>: From factual accuracy to coherence to safety</li>
<li><strong>Context sensitivity</strong>: Performance can vary dramatically across different topics and scenarios</li>
<li><strong>Subjectivity</strong>: Many aspects of LLM outputs require human judgment</li>
<li><strong>Rapid evolution</strong>: Evaluation frameworks need to keep pace with rapidly advancing capabilities</li>
</ol>
</section>
<section id="building-a-systematic-evaluation-framework" class="level2">
<h2 class="anchored" data-anchor-id="building-a-systematic-evaluation-framework">Building a Systematic Evaluation Framework</h2>
<p>A comprehensive LLM evaluation framework should include:</p>
<section id="clearly-defined-evaluation-dimensions" class="level3">
<h3 class="anchored" data-anchor-id="clearly-defined-evaluation-dimensions">1. Clearly Defined Evaluation Dimensions</h3>
<p>Some important dimensions to consider:</p>
<ul>
<li><strong>Factual accuracy</strong>: Does the LLM provide correct information?</li>
<li><strong>Relevance</strong>: Does the response address the query appropriately?</li>
<li><strong>Coherence</strong>: Is the response logically structured and consistent?</li>
<li><strong>Conciseness</strong>: Does the response avoid unnecessary verbosity?</li>
<li><strong>Safety</strong>: Does the model avoid harmful, unethical, or biased outputs?</li>
<li><strong>Format adherence</strong>: Does the output follow requested formats?</li>
</ul>
</section>
<section id="reference-datasets" class="level3">
<h3 class="anchored" data-anchor-id="reference-datasets">2. Reference Datasets</h3>
<p>For effective evaluation, you need appropriate datasets:</p>
<ul>
<li><strong>Benchmark datasets</strong>: Standard datasets like MMLU, HumanEval, etc., for comparative evaluation</li>
<li><strong>Domain-specific datasets</strong>: Tailored to your application area</li>
<li><strong>Adversarial examples</strong>: Test cases designed to probe specific weaknesses</li>
<li><strong>Real-world examples</strong>: Actual queries from your target use case</li>
</ul>
</section>
<section id="evaluation-methods" class="level3">
<h3 class="anchored" data-anchor-id="evaluation-methods">3. Evaluation Methods</h3>
<p>Different aspects of LLM performance require different evaluation strategies:</p>
<section id="automated-evaluation" class="level4">
<h4 class="anchored" data-anchor-id="automated-evaluation">Automated Evaluation</h4>
<ul>
<li><strong>Reference-based metrics</strong>: Compare against ground truth using metrics like BLEU, ROUGE, etc.</li>
<li><strong>Model-based evaluation</strong>: Use another LLM (often a more powerful one) to evaluate outputs</li>
<li><strong>Rule-based checkers</strong>: Verify specific constraints (e.g., format validation)</li>
</ul>
</section>
<section id="human-evaluation" class="level4">
<h4 class="anchored" data-anchor-id="human-evaluation">Human Evaluation</h4>
<ul>
<li><strong>Expert review</strong>: Domain experts assess specific aspects</li>
<li><strong>Comparative ranking</strong>: Side-by-side comparison of different models</li>
<li><strong>User feedback</strong>: Real-world user reactions and preferences</li>
</ul>
</section>
</section>
</section>
<section id="implementing-evaluation-with-weights-biases-sweeps" class="level2">
<h2 class="anchored" data-anchor-id="implementing-evaluation-with-weights-biases-sweeps">Implementing Evaluation with Weights &amp; Biases Sweeps</h2>
<p>Let’s look at how we can implement systematic LLM evaluation using W&amp;B Sweeps.</p>
<section id="setting-up-the-evaluation-framework" class="level3">
<h3 class="anchored" data-anchor-id="setting-up-the-evaluation-framework">Setting Up the Evaluation Framework</h3>
<p>Here’s a simplified approach from my <a href="https://github.com/ayulockin/llm-eval-sweep">llm-eval-sweep</a> repository:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> wandb</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> wandb.sdk.data_types <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> WeightsTable</span>
<span id="cb1-3"></span>
<span id="cb1-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize W&amp;B run</span></span>
<span id="cb1-5">run <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> wandb.init(project<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"llm-evaluation"</span>)</span>
<span id="cb1-6"></span>
<span id="cb1-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define a simple dataset for QA evaluation</span></span>
<span id="cb1-8">qa_pairs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb1-9">    {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"question"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"What is the capital of France?"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"reference"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Paris"</span>},</span>
<span id="cb1-10">    {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"question"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Who wrote Romeo and Juliet?"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"reference"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"William Shakespeare"</span>},</span>
<span id="cb1-11">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># More examples...</span></span>
<span id="cb1-12">]</span>
<span id="cb1-13"></span>
<span id="cb1-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define LLM function (could be OpenAI, Anthropic, or any other provider)</span></span>
<span id="cb1-15"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> get_llm_response(question, temperature, max_tokens):</span>
<span id="cb1-16">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Implementation depends on your LLM provider</span></span>
<span id="cb1-17">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Sample response"</span></span>
<span id="cb1-18"></span>
<span id="cb1-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Track model outputs and evaluations</span></span>
<span id="cb1-20">eval_table <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> wandb.Table(columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"question"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"reference"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"response"</span>, </span>
<span id="cb1-21">                                 <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"accuracy_score"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"relevance_score"</span>])</span>
<span id="cb1-22"></span>
<span id="cb1-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate scores using another LLM as judge</span></span>
<span id="cb1-24"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> evaluate_response(question, reference, response):</span>
<span id="cb1-25">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Implementation of LLM-as-judge</span></span>
<span id="cb1-26">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"accuracy"</span>: <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.85</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"relevance"</span>: <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.9</span>}</span>
<span id="cb1-27"></span>
<span id="cb1-28"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Run evaluation for each example</span></span>
<span id="cb1-29"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> qa <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> qa_pairs:</span>
<span id="cb1-30">    response <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_llm_response(</span>
<span id="cb1-31">        qa[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"question"</span>], </span>
<span id="cb1-32">        temperature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>, </span>
<span id="cb1-33">        max_tokens<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span></span>
<span id="cb1-34">    )</span>
<span id="cb1-35">    </span>
<span id="cb1-36">    scores <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> evaluate_response(qa[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"question"</span>], qa[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"reference"</span>], response)</span>
<span id="cb1-37">    </span>
<span id="cb1-38">    eval_table.add_data(</span>
<span id="cb1-39">        qa[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"question"</span>],</span>
<span id="cb1-40">        qa[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"reference"</span>],</span>
<span id="cb1-41">        response,</span>
<span id="cb1-42">        scores[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"accuracy"</span>],</span>
<span id="cb1-43">        scores[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"relevance"</span>]</span>
<span id="cb1-44">    )</span>
<span id="cb1-45"></span>
<span id="cb1-46"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Log the evaluation results</span></span>
<span id="cb1-47">wandb.log({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"evaluations"</span>: eval_table})</span></code></pre></div>
</section>
<section id="optimizing-with-wb-sweeps" class="level3">
<h3 class="anchored" data-anchor-id="optimizing-with-wb-sweeps">Optimizing with W&amp;B Sweeps</h3>
<p>The real power comes when we use Sweeps to systematically explore different prompt strategies and model parameters:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">sweep_configuration <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb2-2">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"method"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"grid"</span>,</span>
<span id="cb2-3">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"parameters"</span>: {</span>
<span id="cb2-4">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"temperature"</span>: {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"values"</span>: [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>]},</span>
<span id="cb2-5">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"prompt_template"</span>: {</span>
<span id="cb2-6">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"values"</span>: [</span>
<span id="cb2-7">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Answer the following question: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{question}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>,</span>
<span id="cb2-8">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Given the question '</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{question}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">', provide a concise answer."</span>,</span>
<span id="cb2-9">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Answer this question accurately and briefly: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{question}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="cb2-10">            ]</span>
<span id="cb2-11">        },</span>
<span id="cb2-12">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_tokens"</span>: {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"values"</span>: [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span>]}</span>
<span id="cb2-13">    }</span>
<span id="cb2-14">}</span>
<span id="cb2-15"></span>
<span id="cb2-16">sweep_id <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> wandb.sweep(sweep_configuration, project<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"llm-evaluation"</span>)</span>
<span id="cb2-17"></span>
<span id="cb2-18"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> sweep_function():</span>
<span id="cb2-19">    run <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> wandb.init()</span>
<span id="cb2-20">    </span>
<span id="cb2-21">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get sweep parameters</span></span>
<span id="cb2-22">    temperature <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> wandb.config.temperature</span>
<span id="cb2-23">    prompt_template <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> wandb.config.prompt_template</span>
<span id="cb2-24">    max_tokens <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> wandb.config.max_tokens</span>
<span id="cb2-25">    </span>
<span id="cb2-26">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Run evaluation with these parameters</span></span>
<span id="cb2-27">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ... similar to previous code, but using sweep parameters</span></span>
<span id="cb2-28">    </span>
<span id="cb2-29">wandb.agent(sweep_id, function<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sweep_function)</span></code></pre></div>
<p>This approach allows us to systematically explore the impact of different parameters on model performance, and visualize the results in the W&amp;B UI.</p>
</section>
</section>
<section id="case-study-math-problem-evaluation" class="level2">
<h2 class="anchored" data-anchor-id="case-study-math-problem-evaluation">Case Study: Math Problem Evaluation</h2>
<p>One interesting application of this approach is evaluating LLM performance on mathematical problems.</p>
<p>For mathematical problems, we might define specialized evaluation dimensions:</p>
<ol type="1">
<li><strong>Correctness of final answer</strong></li>
<li><strong>Validity of the solution approach</strong></li>
<li><strong>Step-by-step reasoning quality</strong></li>
</ol>
<p>Here’s how we might adapt our evaluation framework:</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">math_problems <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb3-2">    {</span>
<span id="cb3-3">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"question"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Solve for x: 2x + 5 = 15"</span>,</span>
<span id="cb3-4">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"reference_answer"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"x = 5"</span>,</span>
<span id="cb3-5">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"reference_solution"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"2x + 5 = 15</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">2x = 10</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">x = 5"</span></span>
<span id="cb3-6">    },</span>
<span id="cb3-7">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># More problems...</span></span>
<span id="cb3-8">]</span>
<span id="cb3-9"></span>
<span id="cb3-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define specialized math evaluation</span></span>
<span id="cb3-11"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> evaluate_math_solution(problem, reference_answer, reference_solution, response):</span>
<span id="cb3-12">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract final answer from the response</span></span>
<span id="cb3-13">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Analyze solution approach</span></span>
<span id="cb3-14">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Score step-by-step reasoning</span></span>
<span id="cb3-15">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> {</span>
<span id="cb3-16">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"answer_correctness"</span>: <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Binary or graded</span></span>
<span id="cb3-17">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"approach_validity"</span>: <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.9</span>,   <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># How valid was the solution approach</span></span>
<span id="cb3-18">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"reasoning_quality"</span>: <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.8</span>    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Quality of intermediate steps</span></span>
<span id="cb3-19">    }</span></code></pre></div>
</section>
<section id="visualizing-and-interpreting-results" class="level2">
<h2 class="anchored" data-anchor-id="visualizing-and-interpreting-results">Visualizing and Interpreting Results</h2>
<p>After running our evaluations, W&amp;B gives us powerful visualization capabilities:</p>
<ol type="1">
<li><strong>Parallel coordinates plots</strong>: See how different parameters affect various metrics</li>
<li><strong>Scatter plots</strong>: Identify relationships between different evaluation dimensions</li>
<li><strong>Tables with rich media</strong>: Examine individual examples with detailed scoring</li>
</ol>
<p>These visualizations help identify:</p>
<ul>
<li><strong>Patterns of failure</strong>: Common scenarios where the model struggles</li>
<li><strong>Parameter sensitivity</strong>: How temperature, prompt structure, etc. affect performance</li>
<li><strong>Trade-offs</strong>: Where improving one metric might harm another</li>
</ul>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Effective LLM evaluation requires a systematic approach that addresses multiple dimensions of performance. By using tools like W&amp;B Sweeps, we can:</p>
<ol type="1">
<li>Define clear evaluation criteria</li>
<li>Test across diverse examples</li>
<li>Systematically explore different parameters</li>
<li>Visualize and analyze results</li>
</ol>
<p>This approach not only helps in selecting the right models and parameters but also in identifying specific weaknesses that need addressing.</p>
<p>Remember that evaluation is not a one-time activity but an ongoing process. As your use cases evolve and models improve, your evaluation framework should evolve too.</p>
<p>If you’re interested in exploring this topic further, check out my <a href="https://github.com/ayulockin/llm-eval-sweep">llm-eval-sweep</a> repository for more examples and code samples.</p>
<hr>
<p><em>What aspects of LLM evaluation do you find most challenging? I’d love to hear about your experiences in the comments!</em></p>


</section>
</section>

 ]]></description>
  <category>LLMs</category>
  <category>Evaluation</category>
  <category>MLOps</category>
  <category>Tutorials</category>
  <guid>https://ayusht.dev/blog/posts/llm-evaluation.html</guid>
  <pubDate>Mon, 19 Feb 2024 18:30:00 GMT</pubDate>
  <media:content url="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8wNWI9XMFUVxL-YJuhPiqA.png" medium="image" type="image/png"/>
</item>
<item>
  <title>RAG Techniques: From Naive to Advanced</title>
  <dc:creator>Ayush Thakur</dc:creator>
  <link>https://ayusht.dev/blog/posts/rag-techniques-overview.html</link>
  <description><![CDATA[ 




<section id="rag-techniques-from-naive-to-advanced" class="level1">
<h1>RAG Techniques: From Naive to Advanced</h1>
<p>Imagine you’re demoing your company’s new AI chatbot to a potential client. You ask it about their latest product, the one they’ve been working on for months, and what does it return? Information from two years ago about a product they don’t even sell anymore. Frustrating, right?</p>
<p>This is a good example of what retrieval augmented generation (RAG) prevents. It gives LLMs access to content not included in their training data, either because it could not access it, did not access it, or if it was created after the LLMs training date.</p>
<p>In this article, we’ll explore retrieval augmented generation and common RAG techniques to enhance your LLM applications.</p>
<section id="what-is-rag" class="level2">
<h2 class="anchored" data-anchor-id="what-is-rag">What is RAG?</h2>
<p>Retrieval Augmented Generation (RAG) is a technique that combines the power of large language models with the ability to retrieve information from external sources. Rather than relying solely on the knowledge encoded in an LLM’s parameters, RAG allows models to access and reference specific information from a knowledge base.</p>
<p>The basic RAG pipeline consists of three main components:</p>
<ol type="1">
<li><strong>Retriever</strong>: Fetches relevant documents from a knowledge base</li>
<li><strong>Generator</strong>: Uses the retrieved documents as context to generate responses</li>
<li><strong>Knowledge Base</strong>: A collection of documents or information sources</li>
</ol>
</section>
<section id="basic-rag-implementation" class="level2">
<h2 class="anchored" data-anchor-id="basic-rag-implementation">Basic RAG Implementation</h2>
<p>The simplest RAG implementation follows these steps:</p>
<ol type="1">
<li>Convert your documents into embeddings and store them in a vector database</li>
<li>When a query comes in, embed it using the same model</li>
<li>Retrieve the most similar documents based on vector similarity</li>
<li>Feed the retrieved documents as context to the LLM along with the user query</li>
<li>Generate a response based on the provided context</li>
</ol>
<p>Here’s a simplified pseudocode:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Index documents</span></span>
<span id="cb1-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> document <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> documents:</span>
<span id="cb1-3">    embedding <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> embedding_model.encode(document)</span>
<span id="cb1-4">    vector_db.add(document, embedding)</span>
<span id="cb1-5"></span>
<span id="cb1-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Query</span></span>
<span id="cb1-7">query_embedding <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> embedding_model.encode(user_query)</span>
<span id="cb1-8">similar_docs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> vector_db.search(query_embedding, top_k<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)</span>
<span id="cb1-9"></span>
<span id="cb1-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate response</span></span>
<span id="cb1-11">context <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>.join(similar_docs)</span>
<span id="cb1-12">prompt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"""Answer the question based on the context below:</span></span>
<span id="cb1-13"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">Context: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>context<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb1-14"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">Question: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>user_query<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb1-15"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">Answer:"""</span></span>
<span id="cb1-16"></span>
<span id="cb1-17">response <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> llm.generate(prompt)</span></code></pre></div>
</section>
<section id="advanced-rag-techniques" class="level2">
<h2 class="anchored" data-anchor-id="advanced-rag-techniques">Advanced RAG Techniques</h2>
<p>While basic RAG works well for simple use cases, there are several ways to enhance its performance:</p>
<section id="query-transformation" class="level3">
<h3 class="anchored" data-anchor-id="query-transformation">Query Transformation</h3>
<p>One issue with basic RAG is that user queries might not match the exact wording in your documents, leading to poor retrieval. Query transformation addresses this by:</p>
<ol type="1">
<li><strong>Expanding</strong> the query with related terms</li>
<li><strong>Reformulating</strong> the query to better match document content</li>
<li><strong>Breaking down</strong> complex queries into simpler sub-queries</li>
</ol>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Instead of directly using the user query</span></span>
<span id="cb2-2">expanded_query <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> llm.generate(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"""</span></span>
<span id="cb2-3"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">Expand the following query with additional relevant terms:</span></span>
<span id="cb2-4"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">Query: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>user_query<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb2-5"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">Expanded query:"""</span>)</span>
<span id="cb2-6"></span>
<span id="cb2-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Or rewrite it</span></span>
<span id="cb2-8">rewritten_query <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> llm.generate(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"""</span></span>
<span id="cb2-9"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">Rewrite the following query to better match document content:</span></span>
<span id="cb2-10"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">Query: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>user_query<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb2-11"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">Rewritten query:"""</span>)</span></code></pre></div>
</section>
<section id="reranking" class="level3">
<h3 class="anchored" data-anchor-id="reranking">Reranking</h3>
<p>Reranking is one of the most effective ways to boost RAG performance. It works by:</p>
<ol type="1">
<li>Using a fast but less accurate retriever (bi-encoder) to get top-k results</li>
<li>Applying a more powerful but slower model (cross-encoder) to rerank these initial results</li>
</ol>
<p>This gives us the best of both worlds: the speed of approximate retrieval and the accuracy of precise comparison.</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># First retrieval phase - fast but approximate</span></span>
<span id="cb3-2">initial_results <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> vector_db.search(query_embedding, top_k<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>)</span>
<span id="cb3-3"></span>
<span id="cb3-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Second reranking phase - slower but more accurate</span></span>
<span id="cb3-5">reranked_results <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb3-6"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> doc <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> initial_results:</span>
<span id="cb3-7">    score <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cross_encoder_model.score(user_query, doc)</span>
<span id="cb3-8">    reranked_results.append((doc, score))</span>
<span id="cb3-9"></span>
<span id="cb3-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Sort by score and take top results</span></span>
<span id="cb3-11">final_results <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sorted</span>(reranked_results, key<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">lambda</span> x: x[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], reverse<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)[:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>]</span></code></pre></div>
</section>
<section id="context-selection" class="level3">
<h3 class="anchored" data-anchor-id="context-selection">Context Selection</h3>
<p>Another challenge in RAG is that too much context can overwhelm the LLM. Techniques for better context selection include:</p>
<ol type="1">
<li><strong>LLM-based pruning</strong>: Use a smaller model to identify and remove irrelevant chunks</li>
<li><strong>LLMLingua</strong>: Compress prompts by removing low-information tokens</li>
<li><strong>Self-critique</strong>: Let the LLM assess the relevance of each chunk before final generation</li>
</ol>
</section>
<section id="hierarchical-rag" class="level3">
<h3 class="anchored" data-anchor-id="hierarchical-rag">Hierarchical RAG</h3>
<p>For large document collections, hierarchical indexing can be more efficient:</p>
<ol type="1">
<li>Create a summary index with document-level embeddings</li>
<li>Maintain a separate, more granular chunk-level index</li>
<li>First search the summary index to identify relevant documents</li>
<li>Then search only the chunks from those documents</li>
</ol>
<p>This two-step approach reduces the search space and improves retrieval efficiency.</p>
</section>
</section>
<section id="modular-rag-framework" class="level2">
<h2 class="anchored" data-anchor-id="modular-rag-framework">Modular RAG Framework</h2>
<p>Rather than thinking of RAG as a fixed pipeline, consider it a modular framework where each component can be optimized independently:</p>
<ul>
<li><strong>Enhanced Search</strong>: Search across various data sources simultaneously</li>
<li><strong>RAG Fusion</strong>: Use multiple query strategies and combine results</li>
<li><strong>Memory Integration</strong>: Let the LLM guide retrieval based on conversation history</li>
<li><strong>Smart Routing</strong>: Direct queries to the most appropriate data sources</li>
<li><strong>Task Adapter</strong>: Tailor RAG for specific downstream tasks</li>
</ul>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>RAG is a powerful technique that can significantly enhance the capabilities of LLMs by grounding them with external knowledge. By implementing advanced RAG techniques such as query transformation, reranking, and context selection, you can build more accurate, relevant, and efficient AI systems.</p>
<p>The field is rapidly evolving, with new approaches emerging regularly. In future articles, we’ll explore adaptive RAG, multimodal RAG, and graph-based RAG systems in more detail.</p>
<hr>
<p><em>This article is based on my more comprehensive guide on <a href="https://wandb.ai/site/articles/rag-techniques/">Weights &amp; Biases</a>.</em></p>


</section>
</section>

 ]]></description>
  <category>LLMs</category>
  <category>RAG</category>
  <category>Machine Learning</category>
  <category>Tutorials</category>
  <guid>https://ayusht.dev/blog/posts/rag-techniques-overview.html</guid>
  <pubDate>Thu, 14 Dec 2023 18:30:00 GMT</pubDate>
  <media:content url="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Yt5BrQ5G-9wr4pK_kx5HDQ.jpeg" medium="image" type="image/jpeg"/>
</item>
</channel>
</rss>
